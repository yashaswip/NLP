{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM1PMn7wthG9h68qAZ9XxUD",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yashaswip/NLP/blob/main/POS.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CZ3cQOcgno8W",
        "outputId": "4bbcb65c-db5c-4625-91b6-14f3b13d97e9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package brown to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/brown.zip.\n",
            "[nltk_data] Downloading package universal_tagset to /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/universal_tagset.zip.\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "from nltk.corpus import brown\n",
        "from nltk.tag import tnt\n",
        "\n",
        "nltk.download('brown')\n",
        "nltk.download('universal_tagset')\n",
        "\n",
        "# Load data\n",
        "train_sents = brown.tagged_sents(categories='news', tagset='universal')\n",
        "test_sents = brown.tagged_sents(categories='editorial', tagset='universal')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_features(sentence, index):\n",
        "    \"\"\"Extract features for a word at a specific index.\"\"\"\n",
        "    word = sentence[index][0]\n",
        "    prev_word = sentence[index - 1][0] if index > 0 else '<START>'\n",
        "    next_word = sentence[index + 1][0] if index < len(sentence) - 1 else '<END>'\n",
        "\n",
        "    features = {\n",
        "        'word': word,\n",
        "        'prev_word': prev_word,\n",
        "        'next_word': next_word\n",
        "    }\n",
        "    return features"
      ],
      "metadata": {
        "id": "oOs0haC_nzwG"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Transform sentences into feature sets and labels\n",
        "def transform_data(sentences):\n",
        "    features = []\n",
        "    labels = []\n",
        "    for sentence in sentences:\n",
        "        sentence_features = []\n",
        "        sentence_labels = []\n",
        "        for i in range(len(sentence)):\n",
        "            sentence_features.append(extract_features(sentence, i))\n",
        "            sentence_labels.append(sentence[i][1])\n",
        "        features.append(sentence_features)\n",
        "        labels.append(sentence_labels)\n",
        "    return features, labels\n",
        "\n",
        "# Prepare training data\n",
        "train_features, train_labels = transform_data(train_sents)\n",
        "\n",
        "# Train a simple tagger (NLTK's TnT Tagger as an example)\n",
        "tagger = tnt.TnT()\n",
        "tagger.train(train_sents)"
      ],
      "metadata": {
        "id": "KBxQe8gWn5X3"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare test data\n",
        "test_features, test_labels = transform_data(test_sents)\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy = tagger.evaluate(test_sents)\n",
        "print(f'Accuracy: {accuracy:.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pptrDoVbn-N0",
        "outputId": "a2eca8c7-eee6-45ec-9e7e-bea963f7ae28"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-6-4320202ce464>:5: DeprecationWarning: \n",
            "  Function evaluate() has been deprecated.  Use accuracy(gold)\n",
            "  instead.\n",
            "  accuracy = tagger.evaluate(test_sents)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.8700\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install nltk\n",
        "import nltk\n",
        "\n",
        "nltk.download('punkt')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X6zqPJG6owX2",
        "outputId": "a0084b72-eb89-4f58-8af1-82e13da250eb"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2024.5.15)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.4)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def tag_sentence(sentence):\n",
        "    tokens = nltk.word_tokenize(sentence)\n",
        "    tagged = tagger.tag(tokens)\n",
        "    return tagged\n",
        "\n",
        "# Example usage\n",
        "sentence = \"The quick brown fox jumps over the lazy dog.\"\n",
        "print(tag_sentence(sentence))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I-Weu2L2oClI",
        "outputId": "8d5e8bb1-bdef-4b52-bcf9-151e206352ba"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('The', 'DET'), ('quick', 'ADJ'), ('brown', 'NOUN'), ('fox', 'Unk'), ('jumps', 'Unk'), ('over', 'ADP'), ('the', 'DET'), ('lazy', 'ADJ'), ('dog', 'NOUN'), ('.', '.')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Example usage\n",
        "sentence = \"She sells seashells by the seashore.\"\n",
        "print(tag_sentence(sentence))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s5OefE0YoTpT",
        "outputId": "a7eb96d5-1bd4-4628-9e95-30309cd910ae"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('She', 'PRON'), ('sells', 'VERB'), ('seashells', 'Unk'), ('by', 'ADP'), ('the', 'DET'), ('seashore', 'NOUN'), ('.', '.')]\n"
          ]
        }
      ]
    }
  ]
}